{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Konnexions Final Project\n",
    "### Spam and Ham e-mail Classifier\n",
    "<u>In this project we will classify mails into ham and spam mails using machine learning algorithm with the assumption that words are independent of each other</u>\n",
    "\n",
    "Author: Mayank Gajwe<br>\n",
    "Roll: 21052080"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Importing Libraries\n",
    "\n",
    "This also includes nltk which is Natural Language ToolKit that includes the list of stopwords to be used to pre process the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the Dataset\n",
    "This Dataset includes <u>5728</u> mails which are categorized int 'spam' and 'not spam'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Subject: naturally irresistible your corporate...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Subject: the stock trading gunslinger  fanny i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Subject: unbelievable new homes made easy  im ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Subject: 4 color printing special  request add...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Subject: do not have money , get software cds ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  spam\n",
       "0  Subject: naturally irresistible your corporate...     1\n",
       "1  Subject: the stock trading gunslinger  fanny i...     1\n",
       "2  Subject: unbelievable new homes made easy  im ...     1\n",
       "3  Subject: 4 color printing special  request add...     1\n",
       "4  Subject: do not have money , get software cds ...     1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./emails.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the Dataset : (5728, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "text    0\n",
       "spam    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Shape of the Dataset :\",df.shape)\n",
    "df.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above data is Clean and is not missing any values\n",
    "\n",
    "#### Downloading NLTK Stopwords\n",
    "\n",
    "Stopwords are the English words which does not add much meaning to a sentence. They can safely be ignored without sacrificing the meaning of the sentence. For example, the words like the, he, have etc. Such words are already captured this in corpus named corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Mayank\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Pre-Processing the Text\n",
    "\n",
    "The mail text is processed in the function 'text_process' wherein the first parts removes all the punctuation in the sentence and then joins the words to create an object separated by commas\n",
    "The second part checks if the words are present in the stopwords(explained in the markdown above) list. If present, they are ignored, if not, they are added to the clearWords variable and the function returns the clearWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_process(mail):\n",
    "\n",
    "    removePunc = [char for char in mail if char not in string.punctuation]\n",
    "    removePunc = ''.join(removePunc)\n",
    "\n",
    "    clearWords = [word for word in removePunc.split() if word.lower() not in stopwords.words('english')]\n",
    "\n",
    "    return clearWords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function 'text_process' is applied to the DataFrame 'text' which contains the text in the mail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [Subject, naturally, irresistible, corporate, ...\n",
       "1    [Subject, stock, trading, gunslinger, fanny, m...\n",
       "2    [Subject, unbelievable, new, homes, made, easy...\n",
       "3    [Subject, 4, color, printing, special, request...\n",
       "4    [Subject, money, get, software, cds, software,...\n",
       "5    [Subject, great, nnews, hello, welcome, medzon...\n",
       "6    [Subject, hot, play, motion, homeland, securit...\n",
       "7    [Subject, save, money, buy, getting, thing, tr...\n",
       "8    [Subject, undeliverable, home, based, business...\n",
       "9    [Subject, save, money, buy, getting, thing, tr...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'].head(10).apply(text_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(analyzer=text_process).fit_transform(df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(vect, df['spam'], test_size=0.20, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4518    0\n",
       "4472    0\n",
       "799     1\n",
       "4809    0\n",
       "1043    1\n",
       "Name: spam, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data:  4582\n",
      "Testing Data:  1146\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Data: \",y_train.size)\n",
    "print(\"Testing Data: \",y_test.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 3638)\t1\n",
      "  (0, 21485)\t1\n",
      "  (0, 32099)\t1\n",
      "  (0, 33656)\t1\n",
      "  (0, 1821)\t1\n",
      "  (0, 9165)\t1\n",
      "  (0, 36899)\t1\n",
      "  (0, 24418)\t1\n",
      "  (0, 2126)\t1\n",
      "  (0, 916)\t1\n",
      "  (0, 19886)\t1\n",
      "  (0, 304)\t1\n",
      "  (0, 6391)\t1\n",
      "  (0, 25629)\t1\n",
      "  (0, 34400)\t1\n",
      "  (0, 21852)\t2\n",
      "  (0, 17693)\t1\n",
      "  (0, 28712)\t1\n",
      "  (0, 28707)\t1\n",
      "  (0, 1223)\t1\n",
      "  (0, 9325)\t1\n",
      "  (0, 35840)\t1\n",
      "  (0, 357)\t1\n",
      "  (0, 32338)\t1\n",
      "  (0, 927)\t2\n",
      "  :\t:\n",
      "  (4, 20744)\t1\n",
      "  (4, 30734)\t1\n",
      "  (4, 15504)\t1\n",
      "  (4, 8764)\t1\n",
      "  (4, 30710)\t1\n",
      "  (4, 14548)\t1\n",
      "  (4, 20107)\t1\n",
      "  (4, 25143)\t1\n",
      "  (4, 18910)\t1\n",
      "  (4, 35179)\t1\n",
      "  (4, 25918)\t1\n",
      "  (4, 24425)\t1\n",
      "  (4, 22069)\t1\n",
      "  (4, 16684)\t1\n",
      "  (4, 35611)\t1\n",
      "  (4, 27428)\t1\n",
      "  (4, 27412)\t1\n",
      "  (4, 28398)\t1\n",
      "  (4, 23752)\t1\n",
      "  (4, 30454)\t1\n",
      "  (4, 10483)\t1\n",
      "  (4, 6215)\t1\n",
      "  (4, 32028)\t1\n",
      "  (4, 28064)\t1\n",
      "  (4, 4890)\t1\n"
     ]
    }
   ],
   "source": [
    "print(X_train[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "model = MultinomialNB()\n",
    "classifier = model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 ... 0 0 0]\n",
      "[0 0 1 ... 0 0 0] \n",
      "\n",
      "[0 0 1 ... 1 0 1]\n",
      "[0 0 1 ... 0 0 1] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted_training = classifier.predict(X_train)\n",
    "predicted_testing = classifier.predict(X_test)\n",
    "\n",
    "print(predicted_training)\n",
    "print(y_train.values,'\\n')\n",
    "print(predicted_testing)\n",
    "print(y_test.values,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3475\n",
      "           1       0.99      1.00      1.00      1107\n",
      "\n",
      "    accuracy                           1.00      4582\n",
      "   macro avg       1.00      1.00      1.00      4582\n",
      "weighted avg       1.00      1.00      1.00      4582\n",
      "\n",
      "Confusion Matrix: \n",
      " [[3466    9]\n",
      " [   2 1105]] \n",
      "\n",
      "Accuracy for training data:  0.9975993016150153\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "predict = classifier.predict(X_train)\n",
    "print(classification_report(y_train, predict))\n",
    "print('Confusion Matrix: \\n', confusion_matrix(y_train, predict),'\\n')\n",
    "print('Accuracy for training data: ', accuracy_score(y_train, predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 ... 1 0 1]\n",
      "[0 0 1 ... 0 0 1]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99       885\n",
      "           1       0.95      0.99      0.97       261\n",
      "\n",
      "    accuracy                           0.99      1146\n",
      "   macro avg       0.97      0.99      0.98      1146\n",
      "weighted avg       0.99      0.99      0.99      1146\n",
      "\n",
      "Confusion Matrix: \n",
      " [[872  13]\n",
      " [  2 259]] \n",
      "\n",
      "Accuracy for testing data:  0.9869109947643979\n"
     ]
    }
   ],
   "source": [
    "print(classifier.predict(X_test))\n",
    "print(y_test.values)\n",
    "predict = classifier.predict(X_test)\n",
    "print(classification_report(y_test, predict))\n",
    "print('Confusion Matrix: \\n', confusion_matrix(y_test, predict),'\\n')\n",
    "print('Accuracy for testing data: ', accuracy_score(y_test, predict))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e8f4faf11bb1c499f7813a67752444782e7c620cd6863ca267fced227a9725a6"
  },
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
